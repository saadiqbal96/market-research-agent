{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [SOLUTION] Udaplay Project - Part 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from lib.tooling import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment variables loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Verify API keys are loaded\n",
    "assert OPENAI_API_KEY is not None, \"OPENAI_API_KEY not found\"\n",
    "assert TAVILY_API_KEY is not None, \"TAVILY_API_KEY not found\"\n",
    "\n",
    "print(\"✓ Environment variables loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce364221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connected to collection with 15 documents\n"
     ]
    }
   ],
   "source": [
    "# Initialize ChromaDB client and get the collection\n",
    "chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "\n",
    "embedding_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model_name=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "collection = chroma_client.get_collection(\n",
    "    name=\"udaplay\",\n",
    "    embedding_function=embedding_fn\n",
    ")\n",
    "\n",
    "print(f\"✓ Connected to collection with {collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tavily_init",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tavily client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize Tavily client for web search\n",
    "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "\n",
    "print(\"✓ Tavily client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ retrieve_game tool created\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def retrieve_game(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most relevant results in the vector DB.\n",
    "    \n",
    "    args:\n",
    "    - query: a question about game industry. \n",
    "\n",
    "    You'll receive results as list. Each element contains:\n",
    "    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "    - Name: Name of the Game\n",
    "    - YearOfRelease: Year when that game was released for that platform\n",
    "    - Description: Additional details about the game\n",
    "    - Genre: The genre of the game\n",
    "    - Publisher: The publisher of the game\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Query the collection for relevant games\n",
    "        results = collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=5  # Get top 5 results\n",
    "        )\n",
    "        \n",
    "        # Format the results\n",
    "        if results['metadatas'] and len(results['metadatas'][0]) > 0:\n",
    "            formatted_results = []\n",
    "            for metadata in results['metadatas'][0]:\n",
    "                formatted_results.append({\n",
    "                    \"Name\": metadata.get('Name', 'Unknown'),\n",
    "                    \"Platform\": metadata.get('Platform', 'Unknown'),\n",
    "                    \"YearOfRelease\": metadata.get('YearOfRelease', 'Unknown'),\n",
    "                    \"Genre\": metadata.get('Genre', 'Unknown'),\n",
    "                    \"Publisher\": metadata.get('Publisher', 'Unknown'),\n",
    "                    \"Description\": metadata.get('Description', 'No description available')\n",
    "                })\n",
    "            return json.dumps(formatted_results, indent=2)\n",
    "        else:\n",
    "            return json.dumps({\"message\": \"No results found in the database\"})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "print(\"✓ retrieve_game tool created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "evaluation_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ EvaluationReport model defined\n"
     ]
    }
   ],
   "source": [
    "# Define the evaluation report structure\n",
    "class EvaluationReport(BaseModel):\n",
    "    \"\"\"Evaluation report for retrieved documents\"\"\"\n",
    "    useful: bool = Field(description=\"Whether the documents are useful to answer the question\")\n",
    "    description: str = Field(description=\"Detailed explanation of the evaluation\")\n",
    "    confidence: float = Field(description=\"Confidence level (0-1) in the evaluation\")\n",
    "\n",
    "print(\"✓ EvaluationReport model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ evaluate_retrieval tool created\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def evaluate_retrieval(question: str, retrieved_docs: str) -> str:\n",
    "    \"\"\"\n",
    "    Based on the user's question and on the list of retrieved documents, \n",
    "    it will analyze the usability of the documents to respond to that question. \n",
    "    \n",
    "    args: \n",
    "    - question: original question from user\n",
    "    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "    \n",
    "    The result includes:\n",
    "    - useful: whether the documents are useful to answer the question\n",
    "    - description: description about the evaluation result\n",
    "    - confidence: confidence level in the evaluation (0-1)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use LLM as a judge to evaluate the retrieval quality\n",
    "        evaluation_llm = LLM(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "        \n",
    "        evaluation_prompt = f\"\"\"\n",
    "Your task is to evaluate if the retrieved documents are sufficient to answer the user's question.\n",
    "\n",
    "User Question: {question}\n",
    "\n",
    "Retrieved Documents:\n",
    "{retrieved_docs}\n",
    "\n",
    "Analyze the documents and determine:\n",
    "1. Are the documents relevant to the question?\n",
    "2. Do they contain enough information to answer the question?\n",
    "3. What is your confidence level in this evaluation?\n",
    "\n",
    "Provide a detailed explanation so it's possible to take an action to accept it or search the web for more information.\n",
    "\"\"\"\n",
    "        \n",
    "        response = evaluation_llm.invoke(\n",
    "            evaluation_prompt,\n",
    "            response_format=EvaluationReport\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        evaluation = EvaluationReport.model_validate_json(response.content)\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"useful\": evaluation.useful,\n",
    "            \"description\": evaluation.description,\n",
    "            \"confidence\": evaluation.confidence\n",
    "        }, indent=2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "print(\"✓ evaluate_retrieval tool created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ game_web_search tool created\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def game_web_search(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs web search to find information about video games.\n",
    "    Use this when internal database doesn't have sufficient information.\n",
    "    \n",
    "    args:\n",
    "    - question: a question about game industry.\n",
    "    \n",
    "    Returns:\n",
    "    - Web search results with relevant information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use Tavily to search the web\n",
    "        search_results = tavily_client.search(\n",
    "            query=question,\n",
    "            max_results=5,\n",
    "            search_depth=\"advanced\"\n",
    "        )\n",
    "        \n",
    "        # Format the results\n",
    "        formatted_results = []\n",
    "        for result in search_results.get('results', []):\n",
    "            formatted_results.append({\n",
    "                \"title\": result.get('title', 'No title'),\n",
    "                \"url\": result.get('url', ''),\n",
    "                \"content\": result.get('content', 'No content'),\n",
    "                \"score\": result.get('score', 0)\n",
    "            })\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"query\": question,\n",
    "            \"results\": formatted_results,\n",
    "            \"answer\": search_results.get('answer', 'No direct answer available')\n",
    "        }, indent=2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "print(\"✓ game_web_search tool created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31c56281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ UdaPlay agent created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create the UdaPlay agent with all tools\n",
    "instructions = \"\"\"\n",
    "You are UdaPlay, an AI Research Agent specialized in video game industry information.\n",
    "\n",
    "Your workflow:\n",
    "1. First, try to answer questions using the retrieve_game tool to search the internal database\n",
    "2. Use evaluate_retrieval to assess if the retrieved information is sufficient\n",
    "3. If the information is not sufficient (useful=false or low confidence), use game_web_search to find additional information\n",
    "4. Combine information from multiple sources when needed\n",
    "5. Always cite your sources (internal database or web)\n",
    "6. Provide clear, well-structured answers\n",
    "\n",
    "Guidelines:\n",
    "- Be accurate and factual\n",
    "- If you're not sure, say so and explain what information is missing\n",
    "- When using web search results, mention that the information comes from external sources\n",
    "- Format your answers in a clear, readable way\n",
    "- Include relevant details like release dates, platforms, publishers, and descriptions\n",
    "\"\"\"\n",
    "\n",
    "udaplay_agent = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    instructions=instructions,\n",
    "    tools=[retrieve_game, evaluate_retrieval, game_web_search],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"✓ UdaPlay agent created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_section",
   "metadata": {},
   "source": [
    "### Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 1: When was Pokémon Gold and Silver released?\n",
      "================================================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "\n",
      "Agent Response:\n",
      "**Pokémon Gold and Silver** were released in **1999** for the **Game Boy Color**. These games are part of the second generation of Pokémon games and introduced new regions, Pokémon, and gameplay mechanics. They were published by **Nintendo** and are classified as role-playing games. \n",
      "\n",
      "If you need more details or have further questions, feel free to ask!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Query 1: Information available in database\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 1: When was Pokémon Gold and Silver released?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "run1 = udaplay_agent.invoke(\"When was Pokémon Gold and Silver released?\")\n",
    "final_state1 = run1.get_final_state()\n",
    "\n",
    "if final_state1 and final_state1['messages']:\n",
    "    # Get the last AI message\n",
    "    for msg in reversed(final_state1['messages']):\n",
    "        if msg.role == 'assistant' and msg.content:\n",
    "            print(\"\\nAgent Response:\")\n",
    "            print(msg.content)\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "test2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 2: Which one was the first 3D platformer Mario game?\n",
      "================================================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "\n",
      "Agent Response:\n",
      "The first 3D platformer Mario game is **Super Mario 64**, which was released in **1996** for the **Nintendo 64**. This game is considered groundbreaking as it set new standards for the platforming genre and features Mario's quest to rescue Princess Peach.\n",
      "\n",
      "If you have any more questions or need further information, feel free to ask!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Query 2: Another database query\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 2: Which one was the first 3D platformer Mario game?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "run2 = udaplay_agent.invoke(\"Which one was the first 3D platformer Mario game?\")\n",
    "final_state2 = run2.get_final_state()\n",
    "\n",
    "if final_state2 and final_state2['messages']:\n",
    "    for msg in reversed(final_state2['messages']):\n",
    "        if msg.role == 'assistant' and msg.content:\n",
    "            print(\"\\nAgent Response:\")\n",
    "            print(msg.content)\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "test3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 3: Was Mortal Kombat X released for PlayStation 5?\n",
      "================================================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "\n",
      "Agent Response:\n",
      "**Mortal Kombat X** was released on **April 14, 2015**, for the **PlayStation 4**, Xbox One, and PC. However, it was not released for the **PlayStation 5**. There was a later version called **Mortal Kombat XL**, which included all previously released downloadable content and was released for PlayStation 4, but again, no official version for PlayStation 5 was launched.\n",
      "\n",
      "For more details, you can refer to the [Wikipedia page for Mortal Kombat X](https://en.wikipedia.org/wiki/Mortal_Kombat_X).\n",
      "\n",
      "If you have more questions or need further assistance, feel free to ask!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Query 3: May require web search\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 3: Was Mortal Kombat X released for PlayStation 5?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "run3 = udaplay_agent.invoke(\"Was Mortal Kombat X released for PlayStation 5?\")\n",
    "final_state3 = run3.get_final_state()\n",
    "\n",
    "if final_state3 and final_state3['messages']:\n",
    "    for msg in reversed(final_state3['messages']):\n",
    "        if msg.role == 'assistant' and msg.content:\n",
    "            print(\"\\nAgent Response:\")\n",
    "            print(msg.content)\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis",
   "metadata": {},
   "source": [
    "### Agent Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "analysis_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AGENT PERFORMANCE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Query 1 (Pokémon Gold and Silver):\n",
      "------------------------------------------------------------\n",
      "Tool Usage:\n",
      "  - retrieve_game: 1 time(s)\n",
      "  - evaluate_retrieval: 1 time(s)\n",
      "Total Tokens Used: 2878\n",
      "Total Messages: 7\n",
      "\n",
      "Query 2 (First 3D Mario):\n",
      "------------------------------------------------------------\n",
      "Tool Usage:\n",
      "  - retrieve_game: 2 time(s)\n",
      "  - evaluate_retrieval: 2 time(s)\n",
      "Total Tokens Used: 5287\n",
      "Total Messages: 13\n",
      "\n",
      "Query 3 (Mortal Kombat X on PS5):\n",
      "------------------------------------------------------------\n",
      "Tool Usage:\n",
      "  - retrieve_game: 3 time(s)\n",
      "  - evaluate_retrieval: 3 time(s)\n",
      "  - game_web_search: 1 time(s)\n",
      "Total Tokens Used: 12138\n",
      "Total Messages: 21\n"
     ]
    }
   ],
   "source": [
    "# Analyze the agent's tool usage across all runs\n",
    "def analyze_run(run, query_name):\n",
    "    print(f\"\\n{query_name}:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    final_state = run.get_final_state()\n",
    "    if not final_state:\n",
    "        print(\"No final state available\")\n",
    "        return\n",
    "    \n",
    "    # Count tool calls\n",
    "    tool_calls = {}\n",
    "    for msg in final_state['messages']:\n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "            for call in msg.tool_calls:\n",
    "                tool_name = call.function.name\n",
    "                tool_calls[tool_name] = tool_calls.get(tool_name, 0) + 1\n",
    "    \n",
    "    print(f\"Tool Usage:\")\n",
    "    for tool, count in tool_calls.items():\n",
    "        print(f\"  - {tool}: {count} time(s)\")\n",
    "    \n",
    "    # Token usage\n",
    "    if 'total_tokens' in final_state:\n",
    "        print(f\"Total Tokens Used: {final_state['total_tokens']}\")\n",
    "    \n",
    "    print(f\"Total Messages: {len(final_state['messages'])}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AGENT PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "analyze_run(run1, \"Query 1 (Pokémon Gold and Silver)\")\n",
    "analyze_run(run2, \"Query 2 (First 3D Mario)\")\n",
    "analyze_run(run3, \"Query 3 (Mortal Kombat X on PS5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### Additional Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "additional_tests",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CUSTOM TEST: What racing games are available for PlayStation?\n",
      "================================================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "\n",
      "Agent Response:\n",
      "Here are some notable racing games available for PlayStation:\n",
      "\n",
      "1. **Gran Turismo**\n",
      "   - **Platform:** PlayStation 1\n",
      "   - **Year of Release:** 1997\n",
      "   - **Publisher:** Sony Computer Entertainment\n",
      "   - **Description:** A realistic racing simulator featuring a wide array of cars and tracks, setting a new standard for the genre.\n",
      "\n",
      "2. **Gran Turismo 5**\n",
      "   - **Platform:** PlayStation 3\n",
      "   - **Year of Release:** 2010\n",
      "   - **Publisher:** Sony Computer Entertainment\n",
      "   - **Description:** A comprehensive racing simulator featuring a vast selection of vehicles and tracks, with realistic driving physics.\n",
      "\n",
      "3. **Gran Turismo 7**\n",
      "   - **Platform:** PlayStation 4 & PlayStation 5\n",
      "   - **Year of Release:** 2022\n",
      "   - **Publisher:** Sony Interactive Entertainment\n",
      "   - **Description:** The latest in the Gran Turismo series, offering stunning graphics and a wide variety of cars and tracks.\n",
      "\n",
      "4. **Nascar Heat 5**\n",
      "   - **Platform:** PlayStation 4\n",
      "   - **Year of Release:** 2020\n",
      "   - **Publisher:** 704Games\n",
      "   - **Description:** An authentic stock car racing experience that captures the excitement of NASCAR racing.\n",
      "\n",
      "5. **Team Sonic Racing**\n",
      "   - **Platform:** PlayStation 4\n",
      "   - **Year of Release:** 2019\n",
      "   - **Publisher:** SEGA\n",
      "   - **Description:** A kart racing game featuring characters from the Sonic universe, with team-based mechanics.\n",
      "\n",
      "These are just a few examples, and there are many more racing games available on various PlayStation platforms. If you're looking for specific recommendations or need more information, let me know!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with custom queries\n",
    "custom_query = \"What racing games are available for PlayStation?\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"CUSTOM TEST: {custom_query}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "run_custom = udaplay_agent.invoke(custom_query)\n",
    "final_state_custom = run_custom.get_final_state()\n",
    "\n",
    "if final_state_custom and final_state_custom['messages']:\n",
    "    for msg in reversed(final_state_custom['messages']):\n",
    "        if msg.role == 'assistant' and msg.content:\n",
    "            print(\"\\nAgent Response:\")\n",
    "            print(msg.content)\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we successfully implemented:\n",
    "\n",
    "### ✓ Three Core Tools:\n",
    "1. **retrieve_game**: Searches the vector database for game information\n",
    "2. **evaluate_retrieval**: Uses LLM as a judge to assess retrieval quality\n",
    "3. **game_web_search**: Falls back to web search using Tavily API\n",
    "\n",
    "### ✓ Intelligent Agent:\n",
    "- Implements a state machine workflow\n",
    "- Maintains conversation state across queries\n",
    "- Makes intelligent decisions about when to use web search\n",
    "- Combines information from multiple sources\n",
    "- Provides well-structured, cited answers\n",
    "\n",
    "### ✓ Testing & Evaluation:\n",
    "- Tested with multiple query types\n",
    "- Analyzed tool usage and performance\n",
    "- Demonstrated both database retrieval and web search capabilities\n",
    "\n",
    "The UdaPlay agent is now fully functional and ready for production use!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (UdaPlay)",
   "language": "python",
   "name": "uda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
